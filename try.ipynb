{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitbasecondae22aad8c404042ec8ca7532281e9ce1b",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rajiv/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/rajiv/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserScreenName          UserName                 Timestamp  \\\n",
       "0  Melissa Foster   @Melissa_Foster  2021-03-21T11:13:30.000Z   \n",
       "1     CPK.Grownup  @Natasha78210065  2021-03-21T05:56:46.000Z   \n",
       "2   Nathan Blaser    @MorningStarGG  2021-03-21T18:26:15.000Z   \n",
       "3     CPK.Grownup  @Natasha78210065  2021-03-21T05:56:04.000Z   \n",
       "4        Vijeetha      @Vijeetha_NR  2021-03-22T08:43:47.000Z   \n",
       "\n",
       "                                                Text  \\\n",
       "0  The #NakedBaker is cooking up a spicy #hot #ro...   \n",
       "1          Check out #Hot and Spicy's video! #TikTok   \n",
       "2  Still #LIVE @ the #Asylum! #Playing #Overwatch...   \n",
       "3          Check out #Hot and Spicy's video! #TikTok   \n",
       "4  I just don‚Äôt wanna look back & think ‚ÄúI could‚Äô...   \n",
       "\n",
       "                                       Embedded_text Emojis  Comments  Likes  \\\n",
       "0  Seized by Love (The Ryders) - Melissa Foster A...    NaN       NaN    NaN   \n",
       "1  #Hot and Spicy on TikTok\\n#duet with @misscole...    üòä üòÅ       NaN    NaN   \n",
       "2  MorningStarGG - Twitch\\nLifelong gamer and dis...    NaN       NaN    NaN   \n",
       "3  #Hot and Spicy on TikTok\\n#duet with @juicecup...  ü§î üôÑ üò¨       NaN    NaN   \n",
       "4                                                NaN    NaN       NaN    NaN   \n",
       "\n",
       "   Retweets                                         Image link  \\\n",
       "0       1.0  ['https://pbs.twimg.com/card_img/1373244954315...   \n",
       "1       NaN  ['https://pbs.twimg.com/card_img/1373513895961...   \n",
       "2       1.0  ['https://pbs.twimg.com/card_img/1373079231664...   \n",
       "3       NaN  ['https://pbs.twimg.com/card_img/1373513724112...   \n",
       "4       2.0  ['https://pbs.twimg.com/media/ExEjakOVkAISnV2?...   \n",
       "\n",
       "                                           Tweet URL  \n",
       "0  https://twitter.com/Melissa_Foster/status/1373...  \n",
       "1  https://twitter.com/Natasha78210065/status/137...  \n",
       "2  https://twitter.com/MorningStarGG/status/13737...  \n",
       "3  https://twitter.com/Natasha78210065/status/137...  \n",
       "4  https://twitter.com/Vijeetha_NR/status/1373918...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserScreenName</th>\n      <th>UserName</th>\n      <th>Timestamp</th>\n      <th>Text</th>\n      <th>Embedded_text</th>\n      <th>Emojis</th>\n      <th>Comments</th>\n      <th>Likes</th>\n      <th>Retweets</th>\n      <th>Image link</th>\n      <th>Tweet URL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Melissa Foster</td>\n      <td>@Melissa_Foster</td>\n      <td>2021-03-21T11:13:30.000Z</td>\n      <td>The #NakedBaker is cooking up a spicy #hot #ro...</td>\n      <td>Seized by Love (The Ryders) - Melissa Foster A...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>['https://pbs.twimg.com/card_img/1373244954315...</td>\n      <td>https://twitter.com/Melissa_Foster/status/1373...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CPK.Grownup</td>\n      <td>@Natasha78210065</td>\n      <td>2021-03-21T05:56:46.000Z</td>\n      <td>Check out #Hot and Spicy's video! #TikTok</td>\n      <td>#Hot and Spicy on TikTok\\n#duet with @misscole...</td>\n      <td>üòä üòÅ</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['https://pbs.twimg.com/card_img/1373513895961...</td>\n      <td>https://twitter.com/Natasha78210065/status/137...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nathan Blaser</td>\n      <td>@MorningStarGG</td>\n      <td>2021-03-21T18:26:15.000Z</td>\n      <td>Still #LIVE @ the #Asylum! #Playing #Overwatch...</td>\n      <td>MorningStarGG - Twitch\\nLifelong gamer and dis...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>['https://pbs.twimg.com/card_img/1373079231664...</td>\n      <td>https://twitter.com/MorningStarGG/status/13737...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CPK.Grownup</td>\n      <td>@Natasha78210065</td>\n      <td>2021-03-21T05:56:04.000Z</td>\n      <td>Check out #Hot and Spicy's video! #TikTok</td>\n      <td>#Hot and Spicy on TikTok\\n#duet with @juicecup...</td>\n      <td>ü§î üôÑ üò¨</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['https://pbs.twimg.com/card_img/1373513724112...</td>\n      <td>https://twitter.com/Natasha78210065/status/137...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Vijeetha</td>\n      <td>@Vijeetha_NR</td>\n      <td>2021-03-22T08:43:47.000Z</td>\n      <td>I just don‚Äôt wanna look back &amp; think ‚ÄúI could‚Äô...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>['https://pbs.twimg.com/media/ExEjakOVkAISnV2?...</td>\n      <td>https://twitter.com/Vijeetha_NR/status/1373918...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "df = pd.read_csv('outputs/spicy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Wordcloud method\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "def word_cloud(wd_list,filename):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    all_words = ' '.join([text for text in wd_list])\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        width=1600,\n",
    "        height=800,\n",
    "        random_state=1,\n",
    "        colormap='jet',\n",
    "        max_words=80,\n",
    "        max_font_size=200).generate(all_words)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\");\n",
    "    plt.savefig(f'../images/{filename}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "  #text = re.sub(r'', '', text) #Removes Html tag\n",
    "  text = re.sub(r'[^\\ a-zA-Z0-9]+', '', text)  #Removes non alphanumeric\n",
    "  text = re.sub(r'^\\s*|\\s\\s*', ' ', text).strip() #Removes extra whitespace, tabs\n",
    "  stop_words = set(stopwords.words('english')) \n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  text = text.lower().split() #Converts text to lowercase\n",
    "  cleaned_text = list()\n",
    "  for word in text:        \n",
    "    if word in stop_words:    #Removes Stopwords, i.e words that don't convey any meaningful context/sentiments\n",
    "      continue    \n",
    "    word = lemmatizer.lemmatize(word, pos = 'v')    #Lemmatize words, pos = verbs, i.e playing, played becomes play\n",
    "    cleaned_text.append(word)\n",
    "  text = ' '.join(cleaned_text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'marvel lola'"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('static/model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"static/model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 - 0s\n",
      "Sentiment = 0.21663979\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "sent = \"This is a bad morning!!!\"\n",
    "sent = clean_data(sent)\n",
    "tokens = tokenizer.texts_to_sequences([sent])\n",
    "tokens = pad_sequences(tokens, maxlen=280)\n",
    "sentiment = loaded_model.predict(np.array(tokens), batch_size=1, verbose = 2)[0][0]\n",
    "print('Sentiment =', sentiment)\n",
    "if (round(sentiment) == 0):\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}